{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd5b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cffi\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from enum import Enum\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from pathlib import Path\n",
    "from modules.auxiliary import DATA_SEQ_DIR\n",
    "from modules.pytrsomix import TRScalculator, TRSanalyzer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7febe07",
   "metadata": {},
   "source": [
    "'''\n",
    "TODO:\n",
    "Reuse functions some of them work on very similar data\n",
    "Refactor code before exporting to account for suboptimal inputs/do error handling\n",
    "Export functions to the modules - will probably need code rewrite\n",
    "Probably split code below into operations done on fasta files and on blast output - done\n",
    "(maybe provide example script for HPC clusters running on slurm) - pending\n",
    "Make alternative version that could run on Windows(no idea how to do that)\n",
    "Make functions accept args instead of input - currently on hold due to some kind of problem with storing args in variables\n",
    "Please try to break this code as much as possible in many cases i did not introduce any try/catch functionality - report them to me \n",
    "Checkpointing functions to allow restarting from a given step - this is pretty hard with my current skillset \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1301c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(directory_path):\n",
    "    \"\"\"\n",
    "    Ensure that the specified directory exists. If it does not exist, it is created.\n",
    "\n",
    "    Parameters:\n",
    "    - directory_path: The path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"Directory {directory_path} created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4817e56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the directory path where your .fasta files are located.\n",
      "You can provide either a full path or a relative path.\n",
      "Directory path: /home/hubert/TRS-omix/python/data/klebsiella/\n",
      "Enter the value for minimum length of sequence: 100\n",
      "Enter the value for maximum length of sequence: 30000\n",
      "Enter the value for mode to be used: 1\n"
     ]
    }
   ],
   "source": [
    "# Hopefully better version of the above\n",
    "# Prompt user for directory path\n",
    "print(\"Please provide the directory path where your .fasta files are located.\")\n",
    "print(\"You can provide either a full path or a relative path.\")\n",
    "\n",
    "# Loop until a valid directory path is provided\n",
    "while True:\n",
    "    directory_path = input(\"Directory path: \")\n",
    "    directory_path = os.path.abspath(directory_path)\n",
    "    if os.path.exists(directory_path):\n",
    "        break\n",
    "    else:\n",
    "        print(\"Directory does not exist. Please provide a valid directory path.\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        tmin = int(input(\"Enter the value for minimum length of sequence: \"))\n",
    "        tmax = int(input(\"Enter the value for maximum length of sequence: \"))\n",
    "        mode = int(input(\"Enter the value for mode to be used: \"))\n",
    "        break\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid integer.\")\n",
    "\n",
    "\n",
    "# Get directory name\n",
    "directory_name = os.path.basename(directory_path)\n",
    "\n",
    "\n",
    "# Define the directory path for the results\n",
    "results_directory = os.path.join(os.getcwd(), f\"{directory_name}_results\")\n",
    "results_file = f\"{directory_name}_results.csv\"\n",
    "# Create the directory\n",
    "os.makedirs(results_directory, exist_ok=True)\n",
    "\n",
    "# Define the file path for the results within the directory\n",
    "results_file_path = os.path.join(results_directory, results_file)\n",
    "\n",
    "if os.path.exists(results_file_path):\n",
    "    # Ask user if they want to continue\n",
    "    choice = input(f\"Results file '{results_file}' already exists in the current directory. Do you want to continue? (y/n): \")\n",
    "    if choice.lower() != 'y':\n",
    "        print(\"Exiting program.\")\n",
    "        exit()\n",
    "        \n",
    "# Get list of .fasta files in the directory\n",
    "fasta_files = [file for file in os.listdir(directory_path) if file.endswith(\".fasta\")]\n",
    "\n",
    "# Initialize a list to store TRScalculator instances\n",
    "trs_calculators = []\n",
    "\n",
    "# Iterate over each .fasta file\n",
    "for fasta_file in fasta_files:\n",
    "    # Get absolute path of the fasta file\n",
    "    fasta_path = os.path.join(directory_path, fasta_file)\n",
    "\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(fasta_path):\n",
    "        print(f\"File '{fasta_file}' does not exist. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Define the file path for trs.txt (assuming it's located in the working directory)\n",
    "    trs_file = os.path.abspath(\"trs.txt\").encode()\n",
    "    \n",
    "    # Create TRScalculator instance and calculate TRS\n",
    "    trs_calculator = TRScalculator(sequence=fasta_path.encode(), trs=trs_file, tmin=tmin, tmax=tmax, mode=mode)\n",
    "    trs_calculator.calculate()\n",
    "    \n",
    "    # Append the TRScalculator instance to the list\n",
    "    trs_calculators.append(trs_calculator)\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Iterate over each TRScalculator instance\n",
    "for trs_calculator in trs_calculators:\n",
    "    # Extract the result from the calculator\n",
    "    result = trs_calculator.Result\n",
    "    \n",
    "    # Append the result to the list\n",
    "    results_list.append(result)\n",
    "\n",
    "# Concatenate all results into a single DataFrame\n",
    "combined_results = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "#Remove \">\" from >SEQ column\n",
    "combined_results[\">SEQ\"] = combined_results[\">SEQ\"].str.replace(\">\", \"\")\n",
    "\n",
    "# Display the combined results\n",
    "combined_results\n",
    "\n",
    "# Define the CSV file name and directory \n",
    "csv_file_name = directory_name + \"_results.csv\"\n",
    "trs_output_dir = os.path.join(results_directory, \"TRS_output\")\n",
    "os.makedirs(trs_output_dir, exist_ok=True)\n",
    "csv_file_path = os.path.join(trs_output_dir, csv_file_name)\n",
    "\n",
    "# Save combined_results to CSV file\n",
    "combined_results.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdb63b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf727a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "854ef221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L-NoClass</th>\n",
       "      <th>L-No</th>\n",
       "      <th>LFS</th>\n",
       "      <th>Len(LFS)</th>\n",
       "      <th>L-POS(LFS)</th>\n",
       "      <th>R-POS(LFS)</th>\n",
       "      <th>R-NoClass</th>\n",
       "      <th>R-No</th>\n",
       "      <th>RFS</th>\n",
       "      <th>Len(RFS)</th>\n",
       "      <th>L-POS(RFS)</th>\n",
       "      <th>R-POS(RFS)</th>\n",
       "      <th>&gt;SEQ</th>\n",
       "      <th>Len(SEQ)</th>\n",
       "      <th>GENOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>CGGCGGCGG</td>\n",
       "      <td>9</td>\n",
       "      <td>2404</td>\n",
       "      <td>2412</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>CGGCGGCGG</td>\n",
       "      <td>9</td>\n",
       "      <td>3439</td>\n",
       "      <td>3447</td>\n",
       "      <td>CATTGGCCAGTCTCGTTTGACGATGCTGTTGCTGCAGCTTGACCAT...</td>\n",
       "      <td>1026</td>\n",
       "      <td>NC_016845.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>CGGCGGCGG</td>\n",
       "      <td>9</td>\n",
       "      <td>3439</td>\n",
       "      <td>3447</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>GCAGCAGCA</td>\n",
       "      <td>9</td>\n",
       "      <td>4374</td>\n",
       "      <td>4382</td>\n",
       "      <td>TATCATTTTCCGCCAGCACCGGATCGAGCTGACCGCTGAGCGTCAT...</td>\n",
       "      <td>926</td>\n",
       "      <td>NC_016845.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>GCAGCAGCA</td>\n",
       "      <td>9</td>\n",
       "      <td>4374</td>\n",
       "      <td>4382</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>CTGCTGCTG</td>\n",
       "      <td>9</td>\n",
       "      <td>4819</td>\n",
       "      <td>4827</td>\n",
       "      <td>GCGTCAGGGTGGTCCCCTGGATCTCCGCCGGCAGTTCATAGTGCGG...</td>\n",
       "      <td>436</td>\n",
       "      <td>NC_016845.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>CTGCTGCTG</td>\n",
       "      <td>9</td>\n",
       "      <td>4819</td>\n",
       "      <td>4827</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>GCTGCTGCT</td>\n",
       "      <td>9</td>\n",
       "      <td>6481</td>\n",
       "      <td>6489</td>\n",
       "      <td>CCATTGGGTAAATTCCTCGTCGCTCACCTGCAGCGCGCTGGGCACT...</td>\n",
       "      <td>1653</td>\n",
       "      <td>NC_016845.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>GCTGCTGCT</td>\n",
       "      <td>9</td>\n",
       "      <td>6481</td>\n",
       "      <td>6489</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>GGCGGCGGC</td>\n",
       "      <td>9</td>\n",
       "      <td>6778</td>\n",
       "      <td>6786</td>\n",
       "      <td>GAAGCACCCGGAAGCGATTAAAAACCCGTTCTTCCTGCTGGCGCCT...</td>\n",
       "      <td>288</td>\n",
       "      <td>NC_016845.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30504</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>TGGTGGTGG</td>\n",
       "      <td>9</td>\n",
       "      <td>5603843</td>\n",
       "      <td>5603851</td>\n",
       "      <td>14</td>\n",
       "      <td>41</td>\n",
       "      <td>TTCTTCTTC</td>\n",
       "      <td>9</td>\n",
       "      <td>5604969</td>\n",
       "      <td>5604977</td>\n",
       "      <td>TGCCGTCGACCATAAACAGCACCCGATCCGCCTGCTCAATCTCCTG...</td>\n",
       "      <td>1117</td>\n",
       "      <td>NZ_CP113789.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30505</th>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>GCTGCTGCT</td>\n",
       "      <td>9</td>\n",
       "      <td>5605021</td>\n",
       "      <td>5605029</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>CTGCTGCTG</td>\n",
       "      <td>9</td>\n",
       "      <td>5606507</td>\n",
       "      <td>5606515</td>\n",
       "      <td>GAATAATGGTGACCAGGTTGCTGACGATGTAGTACACCACCAGGCC...</td>\n",
       "      <td>1477</td>\n",
       "      <td>NZ_CP113789.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30506</th>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>CTGCTGCTG</td>\n",
       "      <td>9</td>\n",
       "      <td>5606507</td>\n",
       "      <td>5606515</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>CCACCACCA</td>\n",
       "      <td>9</td>\n",
       "      <td>5606927</td>\n",
       "      <td>5606935</td>\n",
       "      <td>GGGCTGCGGATTTTTGTCCTGCTCCCAGGCTTGCCAGATCATGAAA...</td>\n",
       "      <td>411</td>\n",
       "      <td>NZ_CP113789.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30507</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>CCACCACCA</td>\n",
       "      <td>9</td>\n",
       "      <td>5606927</td>\n",
       "      <td>5606935</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>ACGACGACG</td>\n",
       "      <td>9</td>\n",
       "      <td>5607243</td>\n",
       "      <td>5607251</td>\n",
       "      <td>CGAAATCCATTGGCGGGAGTTCATGTTGACGCAAACGAAAACTTTC...</td>\n",
       "      <td>307</td>\n",
       "      <td>NZ_CP113789.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30508</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>ACGACGACG</td>\n",
       "      <td>9</td>\n",
       "      <td>5607243</td>\n",
       "      <td>5607251</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>GCGGCGGCG</td>\n",
       "      <td>9</td>\n",
       "      <td>454</td>\n",
       "      <td>462</td>\n",
       "      <td>TGCCAGAACCTGACGACCATTTTTAGTAGCCATACGAGCACGGAAG...</td>\n",
       "      <td>1170</td>\n",
       "      <td>NZ_CP113789.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30509 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       L-NoClass  L-No        LFS  Len(LFS)  L-POS(LFS)  R-POS(LFS)  \\\n",
       "0              2     4  CGGCGGCGG         9        2404        2412   \n",
       "1              2     4  CGGCGGCGG         9        3439        3447   \n",
       "2              9    26  GCAGCAGCA         9        4374        4382   \n",
       "3             10    29  CTGCTGCTG         9        4819        4827   \n",
       "4             10    28  GCTGCTGCT         9        6481        6489   \n",
       "...          ...   ...        ...       ...         ...         ...   \n",
       "30504          4    12  TGGTGGTGG         9     5603843     5603851   \n",
       "30505         10    28  GCTGCTGCT         9     5605021     5605029   \n",
       "30506         10    29  CTGCTGCTG         9     5606507     5606515   \n",
       "30507          3     8  CCACCACCA         9     5606927     5606935   \n",
       "30508          7    19  ACGACGACG         9     5607243     5607251   \n",
       "\n",
       "       R-NoClass  R-No        RFS  Len(RFS)  L-POS(RFS)  R-POS(RFS)  \\\n",
       "0              2     4  CGGCGGCGG         9        3439        3447   \n",
       "1              9    26  GCAGCAGCA         9        4374        4382   \n",
       "2             10    29  CTGCTGCTG         9        4819        4827   \n",
       "3             10    28  GCTGCTGCT         9        6481        6489   \n",
       "4              2     5  GGCGGCGGC         9        6778        6786   \n",
       "...          ...   ...        ...       ...         ...         ...   \n",
       "30504         14    41  TTCTTCTTC         9     5604969     5604977   \n",
       "30505         10    29  CTGCTGCTG         9     5606507     5606515   \n",
       "30506          3     8  CCACCACCA         9     5606927     5606935   \n",
       "30507          7    19  ACGACGACG         9     5607243     5607251   \n",
       "30508          2     6  GCGGCGGCG         9         454         462   \n",
       "\n",
       "                                                    >SEQ  Len(SEQ)  \\\n",
       "0      CATTGGCCAGTCTCGTTTGACGATGCTGTTGCTGCAGCTTGACCAT...      1026   \n",
       "1      TATCATTTTCCGCCAGCACCGGATCGAGCTGACCGCTGAGCGTCAT...       926   \n",
       "2      GCGTCAGGGTGGTCCCCTGGATCTCCGCCGGCAGTTCATAGTGCGG...       436   \n",
       "3      CCATTGGGTAAATTCCTCGTCGCTCACCTGCAGCGCGCTGGGCACT...      1653   \n",
       "4      GAAGCACCCGGAAGCGATTAAAAACCCGTTCTTCCTGCTGGCGCCT...       288   \n",
       "...                                                  ...       ...   \n",
       "30504  TGCCGTCGACCATAAACAGCACCCGATCCGCCTGCTCAATCTCCTG...      1117   \n",
       "30505  GAATAATGGTGACCAGGTTGCTGACGATGTAGTACACCACCAGGCC...      1477   \n",
       "30506  GGGCTGCGGATTTTTGTCCTGCTCCCAGGCTTGCCAGATCATGAAA...       411   \n",
       "30507  CGAAATCCATTGGCGGGAGTTCATGTTGACGCAAACGAAAACTTTC...       307   \n",
       "30508  TGCCAGAACCTGACGACCATTTTTAGTAGCCATACGAGCACGGAAG...      1170   \n",
       "\n",
       "              GENOME  \n",
       "0        NC_016845.1  \n",
       "1        NC_016845.1  \n",
       "2        NC_016845.1  \n",
       "3        NC_016845.1  \n",
       "4        NC_016845.1  \n",
       "...              ...  \n",
       "30504  NZ_CP113789.1  \n",
       "30505  NZ_CP113789.1  \n",
       "30506  NZ_CP113789.1  \n",
       "30507  NZ_CP113789.1  \n",
       "30508  NZ_CP113789.1  \n",
       "\n",
       "[30509 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can load\n",
    "combined_results = pd.read_csv(csv_file_path)\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc89e02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum available length for SEQ_L and SEQ_R is 50 and 50 respectively.\n",
      "Enter the length of sequence to extract from the start (up to 50): 50\n",
      "Enter the length of sequence to extract from the end (up to 50): 50\n",
      "The results directory has been renamed to: /home/hubert/TRS-omix/python/klebsiella_results_L50_R50\n"
     ]
    }
   ],
   "source": [
    "#Make get maximum values for user input based on what they gave as tmin\n",
    "def calculate_sequence_lengths(tmin):\n",
    "    l_chars_max = tmin // 2\n",
    "    r_chars_max = tmin // 2\n",
    "    return l_chars_max, r_chars_max\n",
    "\n",
    "l_chars_max, r_chars_max = calculate_sequence_lengths(tmin)\n",
    "\n",
    "print(f\"The maximum available length for SEQ_L and SEQ_R is {l_chars_max} and {r_chars_max} respectively.\")\n",
    "\n",
    "l_chars = int(input(f\"Enter the length of sequence to extract from the start (up to {l_chars_max}): \"))\n",
    "r_chars = int(input(f\"Enter the length of sequence to extract from the end (up to {r_chars_max}): \"))\n",
    "\n",
    "# Not very elegant but catch all solution to the problem of bad inputs (i know it does not account for string will work on it)\n",
    "def adjust_input_to_range(user_input, max_val):\n",
    "    if user_input > max_val:\n",
    "        print(f\"Your input was adjusted to {max_val}.\")\n",
    "        return max_val\n",
    "    return user_input\n",
    "\n",
    "l_chars = adjust_input_to_range(l_chars, l_chars_max)\n",
    "r_chars = adjust_input_to_range(r_chars, r_chars_max)\n",
    "\n",
    "def extract_sequences(combined_results, l_chars, r_chars):\n",
    "    # Create new columns SEQ_L and SEQ_R by slicing the sequence column\n",
    "    combined_results['SEQ_L'] = combined_results['>SEQ'].str.slice(0, l_chars)\n",
    "    combined_results['SEQ_R'] = combined_results['>SEQ'].str.slice(-r_chars)    \n",
    "    return combined_results\n",
    "\n",
    "combined_results = extract_sequences(combined_results, l_chars, r_chars)\n",
    "\n",
    "# Generate the new directory name based on user inputs\n",
    "new_results_directory = f\"{results_directory}_L{l_chars}_R{r_chars}\"\n",
    "\n",
    "# Full path for the new directory\n",
    "new_results_directory_path = os.path.join(os.path.dirname(results_directory), new_results_directory)\n",
    "\n",
    "# Check if the new directory name already exists to avoid overwriting\n",
    "if not os.path.exists(new_results_directory_path):\n",
    "    # Rename the existing results directory\n",
    "    os.rename(results_directory, new_results_directory_path)\n",
    "    print(f\"The results directory has been renamed to: {new_results_directory_path}\")\n",
    "else:\n",
    "    print(f\"Directory {new_results_directory_path} already exists. Consider using a different name or removing the existing directory.\")\n",
    "results_directory = new_results_directory_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b414ca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To further protect your email address, consider using a temporary or disposable email address.\n",
      "Enter your email address to access Entrez: hsalamaga@ibb.waw.pl\n"
     ]
    }
   ],
   "source": [
    "# Function to validate email format\n",
    "def validate_email(email):\n",
    "    \"\"\"\n",
    "    Validate email format.\n",
    "\n",
    "    Args:\n",
    "        email (str): Email address to validate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the email format is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    if re.match(r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\", email):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Prompt the user to input their email address\n",
    "while True:\n",
    "    print(\"To further protect your email address, consider using a temporary or disposable email address.\")\n",
    "    user_email = input(\"Enter your email address to access Entrez: \")\n",
    "    # Validate email format\n",
    "    if validate_email(user_email):\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid email address format. Please enter a valid email address.\")\n",
    "\n",
    "# Set the user's email address (required by NCBI)\n",
    "Entrez.email = user_email\n",
    "\n",
    "# Function to fetch organism names from NCBI based on NCBI IDs\n",
    "def fetch_organism_names(ncbi_ids):\n",
    "    \"\"\"\n",
    "    Fetch organism names from NCBI based on NCBI IDs.\n",
    "\n",
    "    Args:\n",
    "        ncbi_ids (list): List of NCBI IDs.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping NCBI IDs to organism names.\n",
    "    \"\"\"\n",
    "    organism_map = {}  # Initialize a dictionary to store the organism names\n",
    "    for ncbi_id in ncbi_ids:\n",
    "        try:\n",
    "            # Fetch the record from NCBI\n",
    "            handle = Entrez.efetch(db=\"nucleotide\", id=ncbi_id, rettype=\"gb\", retmode=\"text\")\n",
    "            record = handle.read()\n",
    "            # Extract the organism information from the record\n",
    "            for line in record.splitlines():\n",
    "                if line.startswith(\"  ORGANISM\"):\n",
    "                    organism = line.split(\"ORGANISM\")[1].strip()\n",
    "                    # Replace spaces with underscores\n",
    "                    organism = organism.replace(\" \", \"_\")\n",
    "                    organism_map[ncbi_id] = organism\n",
    "                    break  # Once organism information is found, break the loop\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching organism name for NCBI ID {ncbi_id}: {e}\")\n",
    "    return organism_map\n",
    "\n",
    "# Read the DataFrame with the combined_results\n",
    "ncbi_ids = combined_results[\"GENOME\"].unique().tolist()\n",
    "\n",
    "# Fetch organism names from NCBI\n",
    "organism_map = fetch_organism_names(ncbi_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad068cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map NCBI IDs to taxonomic names\n",
    "combined_results['Taxonomic_Name'] = combined_results['GENOME'].map(organism_map)\n",
    "\n",
    "# Identify unmatched genomes\n",
    "unmatched_genomes = combined_results[combined_results['Taxonomic_Name'].isnull()]['GENOME'].unique()\n",
    "\n",
    "if len(unmatched_genomes) > 0:\n",
    "    print(f\"Warning: Some genome IDs could not be matched with taxonomic names: {unmatched_genomes}\")\n",
    "\n",
    "# Extract sequences and create sequence IDs\n",
    "combined_results['L_id'] = combined_results['Taxonomic_Name'] + '_L' + combined_results['L-No'].astype(str)\n",
    "combined_results['R_id'] = combined_results['Taxonomic_Name'] + '_R' + combined_results['R-No'].astype(str)\n",
    "\n",
    "# Select relevant columns\n",
    "sequences_df = combined_results[['SEQ_L', 'SEQ_R', 'L_id', 'R_id']]\n",
    "\n",
    "# Save both left and right sequences to a single FASTA file will help with cd-hit\n",
    "trs_output_dir = os.path.join(results_directory,\"TRS_output\")\n",
    "fasta_file_path = os.path.join(trs_output_dir, 'combined_sequences.fasta')\n",
    "with open(fasta_file_path, 'w') as fasta_file:\n",
    "    for _, row in sequences_df.iterrows():\n",
    "        # Write left sequence\n",
    "        fasta_file.write(f'>{row[\"L_id\"]}\\n')\n",
    "        fasta_file.write(f'{row[\"SEQ_L\"]}\\n')\n",
    "        # Write right sequence\n",
    "        fasta_file.write(f'>{row[\"R_id\"]}\\n')\n",
    "        fasta_file.write(f'{row[\"SEQ_R\"]}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "993692f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is possibility of several sequences having the same name as such we need to make sure that all ids are unique\n",
    "def rename_sequences(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Renames sequences in a FASTA file such that each pair of sequences (L and R) shares the same index.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the input FASTA file.\n",
    "        output_file (str): Path to the output FASTA file with renamed sequences.\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\") as input_handle, open(output_file, \"w\") as output_handle:\n",
    "        # Initialize a counter for pairs\n",
    "        pair_index = 1\n",
    "        # Process sequences in pairs\n",
    "        for record in SeqIO.parse(input_handle, \"fasta\"):\n",
    "            original_id = record.id\n",
    "            # Determine whether the sequence is part of a pair (L/R) and assign the same index\n",
    "            # Assuming sequences come in consecutive pairs (L followed by R)\n",
    "            new_id = f\"{original_id}_{pair_index}\"\n",
    "            record.id = new_id\n",
    "            record.description = \"\"\n",
    "            SeqIO.write(record, output_handle, \"fasta\")\n",
    "            \n",
    "            # Increment the pair index after every second sequence to keep the index the same for pairs\n",
    "            if 'R' in original_id:\n",
    "                pair_index += 1\n",
    "\n",
    "# Call the function to rename sequences\n",
    "output_path = os.path.join(trs_output_dir, 'combined_sequences_unique.fasta')   \n",
    "rename_sequences(fasta_file_path, output_path)\n",
    "fasta_combined_file_path = output_path\n",
    "# This function incorporates index into sequence name making it easy to find the original sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb05fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sequence identity threshold (between 0.75 and 1.0): 1\n",
      "The results directory has been renamed to: /home/hubert/TRS-omix/python/klebsiella_results_L50_R50_c1.0\n"
     ]
    }
   ],
   "source": [
    "def run_cdhit(cdhit_path, input_file, output_file, c=None, d=0, m=\"t\", g=0, G=1, sc=0, results_directory=\"results\"):\n",
    "    \"\"\"\n",
    "    Enhanced run CD-HIT program from Python, automatically adjusting 'n' based on sequence identity threshold 'c'.\n",
    "\n",
    "    Parameters:\n",
    "        cdhit_path (str): Path to the CD-HIT executable. If None, will use a globally stored path or prompt the user.\n",
    "        input_file (str): Path to the input FASTA file.\n",
    "        output_file (str): Path to the output file.\n",
    "        c (float): Sequence identity threshold (between 0.4 and 1.0). If None, the user will be prompted.\n",
    "        d (int): Bandwidth of alignment, default is 0.\n",
    "        m (str): Memory limit, default is \"t\" for unlimited.\n",
    "        g (int), G (int), sc (int): Additional CD-HIT parameters with their default values.\n",
    "        results_directory (str): Directory to store the results. Default is \"results\".\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "\n",
    "    global cdhit_path_global\n",
    "\n",
    "    # Function to adjust 'n' based on 'c'\n",
    "    def adjust_word_length(c):\n",
    "        thresholds_n_values = [\n",
    "            (0.95, 10),\n",
    "            (0.90, 8),\n",
    "            (0.88, 7),\n",
    "            (0.85, 6),\n",
    "            (0.80, 5),\n",
    "            (0.75, 4),\n",
    "        ]\n",
    "        if c == 1.0:\n",
    "            return 11\n",
    "        for lower_bound, n_value in thresholds_n_values:\n",
    "            if c >= lower_bound:\n",
    "                return n_value\n",
    "        return None  # Fallback, should not be reached if 'c' is within specified bounds\n",
    "\n",
    "    # Prompt for sequence identity threshold if not provided\n",
    "    if c is None:\n",
    "        c = float(input(\"Enter the sequence identity threshold (between 0.75 and 1.0): \"))\n",
    "        while not 0.75 <= c <= 1.0:\n",
    "            print(\"Error: The sequence identity threshold must be between 0.75 and 1.0.\")\n",
    "            c = float(input(\"Enter the sequence identity threshold (between 0.75 and 1.0): \"))\n",
    "\n",
    "    # Dynamically adjust 'n' based on 'c'\n",
    "    n = adjust_word_length(c)\n",
    "\n",
    "    # Validate and use the CD-HIT path\n",
    "    if cdhit_path is None and 'cdhit_path_global' in globals() and os.path.exists(os.path.join(cdhit_path_global, \"cd-hit\")):\n",
    "        cdhit_path = cdhit_path_global\n",
    "    elif cdhit_path is None or not os.path.exists(os.path.join(cdhit_path, \"cd-hit\")):\n",
    "        cdhit_path = input(\"Enter the directory where CD-HIT is located: \")\n",
    "        if not os.path.exists(os.path.join(cdhit_path, \"cd-hit\")):\n",
    "            raise FileNotFoundError(\"CD-HIT executable not found in the specified directory.\")\n",
    "    cdhit_path_global = cdhit_path\n",
    "\n",
    "    # Ensure the results directory exists\n",
    "    if not os.path.exists(results_directory):\n",
    "        os.makedirs(results_directory)\n",
    "\n",
    "    # Construct the CD-HIT command\n",
    "    cmd = [\n",
    "        os.path.join(cdhit_path, \"cd-hit-est\"),\n",
    "        \"-i\", input_file,\n",
    "        \"-o\", output_file,\n",
    "        \"-c\", str(c),\n",
    "        \"-n\", str(n),\n",
    "        \"-d\", str(d),\n",
    "        \"-M\", m,\n",
    "        \"-g\", str(g),\n",
    "        \"-G\", str(G),\n",
    "        \"-sc\", str(sc)\n",
    "    ]\n",
    "\n",
    "    # Execute CD-HIT command and handle errors\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        new_results_directory = f\"{results_directory}_c{c}\"\n",
    "        if not os.path.exists(new_results_directory):\n",
    "            os.rename(results_directory, new_results_directory)\n",
    "            results_directory = new_results_directory\n",
    "            print(f\"The results directory has been renamed to: {new_results_directory}\")\n",
    "        else:\n",
    "            print(f\"Warning: The directory {new_results_directory} already exists. Results directory was not renamed.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"CD-HIT command failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    return results_directory\n",
    "\n",
    "output_path = os.path.join(results_directory, \"cd-hit_results\")\n",
    "output_file = os.path.join(output_path, \"combined_sequences_unique_cdhit\")\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Run CD-HIT and update results_directory with the potentially new directory name\n",
    "results_directory = run_cdhit(cdhit_path=None, input_file=fasta_combined_file_path, output_file=output_file, results_directory=results_directory)\n",
    "# results_directory now points to the updated directory name, if it was changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7181f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "trs_output_dir = os.path.join(results_directory,\"TRS_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2be51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_ids(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Extract sequence IDs from clusters with more than 2 sequences and save them to a file.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the input cluster data file.\n",
    "        output_file (str): Path to the output file to save sequence IDs.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\") as f, open(output_file, \"w\") as outfile:\n",
    "        current_cluster = []\n",
    "        for line in f:\n",
    "            if line.startswith(\">Cluster\"):\n",
    "                if len(current_cluster) >= 2:\n",
    "                    for seq in current_cluster:\n",
    "                        outfile.write(seq)\n",
    "                current_cluster = []  # Clear current cluster\n",
    "            elif line.strip():  # Proceed if the line is not empty\n",
    "                current_cluster.append(line)  # Add sequence to current cluster\n",
    "        if len(current_cluster) >= 2:\n",
    "            for seq in current_cluster:\n",
    "                outfile.write(seq)\n",
    "# Example usage\n",
    "input_file = os.path.join(results_directory,\"cd-hit_results\",\"combined_sequences_unique_cdhit.clstr\")\n",
    "output_file = os.path.join(results_directory,\"cd-hit_results\",\"combined_sequences_clusters.txt\")\n",
    "extract_sequence_ids(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6493fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sequence_ids(input_file):\n",
    "    \"\"\"\n",
    "    Clean sequence IDs file by removing prefixes and suffixes.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the input file with sequence IDs.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\") as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    with open(input_file, \"w\") as outfile:\n",
    "        for line in lines:\n",
    "            sequence_id = line.split(\">\")[1].split(\"...\")[0].strip()\n",
    "            outfile.write(\">\" + sequence_id + \"\\n\")\n",
    "\n",
    "# Example usage\n",
    "input_file = output_file\n",
    "clean_sequence_ids(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47cdf0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/hubert/TRS-omix/python/klebsiella_results_L50_R50_c1.0/filtered_sequences created.\n",
      "Filtered file created successfully at /home/hubert/TRS-omix/python/klebsiella_results_L50_R50_c1.0/filtered_sequences/filtered_sequences_combined_unique.fasta!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Remove entries in L/R_clusters from the .fasta file \n",
    "\"\"\"\n",
    "def read_fasta_ids(filename):\n",
    "    \"\"\"\n",
    "    Read and return a set of FASTA IDs from a given file, processing the file line by line\n",
    "    to efficiently handle large files.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the FASTA file.\n",
    "\n",
    "    Returns:\n",
    "    - A set of FASTA IDs found in the file.\n",
    "    \"\"\"\n",
    "    fasta_ids = set()\n",
    "    \n",
    "    def process_line(line): #might be useful later\n",
    "        \"\"\"\n",
    "        Process a single line from the FASTA file, adding the ID to the set if the line is a header.\n",
    "        \"\"\"\n",
    "        if line.startswith('>'):\n",
    "            fasta_id = line.strip()[1:]\n",
    "            fasta_ids.add(fasta_id)\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                process_line(line)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {filename} not found. Do not move files during execution!\")\n",
    "\n",
    "    return fasta_ids\n",
    "\n",
    "\n",
    "def filter_fasta_file(input_file, output_file, fasta_ids_to_remove, chunk_size=1024*1024):\n",
    "    \"\"\"\n",
    "    Filter entries from a FASTA file in chunks, removing sequences with IDs in the given set.\n",
    "\n",
    "    Parameters:\n",
    "    - input_file: Path to the input FASTA file.\n",
    "    - output_file: Path where the filtered FASTA file will be saved.\n",
    "    - fasta_ids_to_remove: A set of FASTA IDs to be removed from the input file.\n",
    "    - chunk_size: Size of the chunk to read at a time (in bytes). Default is 1MB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file, 'r') as f_in, open(output_file, 'w') as f_out:\n",
    "            fasta_entry = []  # Stores lines of a single FASTA entry\n",
    "            write_entry = True  # Determines whether the current entry should be written to the output\n",
    "\n",
    "            for line in f_in:\n",
    "                if line.startswith('>'):  # Start of a new FASTA entry\n",
    "                    if fasta_entry:  # If there's an entry to process\n",
    "                        if write_entry:  # If the previous entry is not in the removal list, write it to the file\n",
    "                            f_out.writelines(fasta_entry)\n",
    "                        fasta_entry = []  # Reset for the next entry\n",
    "                        write_entry = True  # Reset flag\n",
    "\n",
    "                    current_fasta_id = line.strip()[1:]\n",
    "                    if current_fasta_id in fasta_ids_to_remove:\n",
    "                        write_entry = False  # Mark for non-writing if ID is in the removal list\n",
    "\n",
    "                fasta_entry.append(line)  # Add current line to the entry\n",
    "\n",
    "            if fasta_entry and write_entry:  # Process the last entry if there's one\n",
    "                f_out.writelines(fasta_entry)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {input_file} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Read fasta IDs from the L_clusters file\n",
    "fasta_ids_to_remove = read_fasta_ids(input_file)\n",
    "fasta_combined_file_path = os.path.join(trs_output_dir, 'combined_sequences_unique.fasta') \n",
    "\n",
    "#Make sure the output directory exists\n",
    "filtered_sequences_directory = os.path.join(results_directory,\"filtered_sequences\")\n",
    "ensure_directory_exists(filtered_sequences_directory)\n",
    "\n",
    "# Filter the sequences_L_unique.fasta file\n",
    "filtered_fasta = os.path.join(filtered_sequences_directory,\"filtered_sequences_combined_unique.fasta\")\n",
    "filter_fasta_file(fasta_combined_file_path,filtered_fasta, fasta_ids_to_remove)\n",
    "\n",
    "print(f\"Filtered file created successfully at {filtered_fasta}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c5c29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fasta_file_clusters(input_file, output_file, fasta_ids_to_include):\n",
    "    \"\"\"\n",
    "    Filters a FASTA file to only include sequences with IDs present in the given set.\n",
    "\n",
    "    Parameters:\n",
    "    - input_file: Path to the input FASTA file.\n",
    "    - output_file: Path where the filtered FASTA file will be saved.\n",
    "    - fasta_ids_to_include: A set of FASTA IDs that should be included in the output file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file, 'r') as f_in, open(output_file, 'w') as f_out:\n",
    "            include_entry = False\n",
    "            for line in f_in:\n",
    "                if line.startswith('>'):\n",
    "                    current_fasta_id = line.strip()[1:]\n",
    "                    if current_fasta_id in fasta_ids_to_include:\n",
    "                        include_entry = True\n",
    "                        f_out.write(line)  # Include the header line for matching IDs\n",
    "                    else:\n",
    "                        include_entry = False  # Do not include entries for non-matching IDs\n",
    "                elif include_entry:\n",
    "                    f_out.write(line)  # Include the sequence lines for matching IDs\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {input_file} was not found. Please check the file path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54dc59e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sequences file created successfully! /home/hubert/TRS-omix/python/klebsiella_results_L50_R50_c1.0/filtered_sequences/cluster_sequences_combined_unique.fasta\n",
      "Directory /home/hubert/TRS-omix/python/klebsiella_results_L50_R50_c1.0/blast_output created.\n",
      "All results files are stored in /home/hubert/TRS-omix/python/klebsiella_results_L50_R50_c1.0/filtered_sequences,\n",
      "please continue analysis by blasting them with 100% identity in tabular format. Directory for the blast output\n",
      "was created at /home/hubert/TRS-omix/python/klebsiella_results_L50_R50_c1.0/blast_output\n"
     ]
    }
   ],
   "source": [
    "# Ensure the filtered_sequences directory exists\n",
    "ensure_directory_exists(filtered_sequences_directory)\n",
    "\n",
    "# Assuming the correct file paths are defined here for cluster files\n",
    "clusters_file = os.path.join(results_directory,\"cd-hit_results\",\"combined_sequences_clusters.txt\") \n",
    "# Read fasta IDs from the clusters file\n",
    "fasta_ids_to_include = read_fasta_ids(clusters_file)\n",
    "\n",
    "# Define the output paths and paths of initial sequences\n",
    "sequences_in_clusters = os.path.join(filtered_sequences_directory, \"cluster_sequences_combined_unique.fasta\")\n",
    "unique_path = os.path.join(trs_output_dir, 'combined_sequences_unique.fasta')\n",
    "\n",
    "\n",
    "# Filter the combined_sequences_unique.fasta file\n",
    "filter_fasta_file_clusters(unique_path, sequences_in_clusters, fasta_ids_to_include)\n",
    "print(f\"Cluster sequences file created successfully! {sequences_in_clusters}\")\n",
    "\n",
    "blast_out_directory = os.path.join(results_directory,\"blast_output\")\n",
    "ensure_directory_exists(blast_out_directory)\n",
    "\n",
    "print(f\"\"\"All results files are stored in {filtered_sequences_directory},\n",
    "please continue analysis by blasting them with 100% identity in tabular format. Directory for the blast output\n",
    "was created at {blast_out_directory}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08b256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
